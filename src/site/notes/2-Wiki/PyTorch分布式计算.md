---
{"dg-publish":true,"title":"PyTorchåˆ†å¸ƒå¼è®¡ç®—","created":"2024-04-01 09:37","updated":"2024-04-01 10:12","tags":["deep-learning","python","pytorch"],"dg-path":"Wiki/PyTorchåˆ†å¸ƒå¼è®¡ç®—.md","permalink":"/Wiki/PyTorchåˆ†å¸ƒå¼è®¡ç®—/","dgPassFrontmatter":true,"noteIcon":"1"}
---


```ad-attention

æœ¬æ–‡æ‰€è¯´çš„åˆ†å¸ƒå¼è®¡ç®—ç‰¹æŒ‡DistributedDataParallel (DDP)ã€‚
```

# Concepts
é¦–å…ˆæˆ‘ä»¬éœ€è¦å…ˆäº†è§£ä¸€äº›æ¦‚å¿µï¼š
- rankï¼šç”¨äºè¡¨ç¤ºè¿›ç¨‹çš„ç¼–å·/åºå·ï¼ˆåœ¨ä¸€äº›ç»“æ„å›¾ä¸­ rank æŒ‡çš„æ˜¯è½¯èŠ‚ç‚¹ï¼Œrank å¯ä»¥çœ‹æˆä¸€ä¸ªè®¡ç®—å•ä½ï¼‰ï¼Œæ¯ä¸€ä¸ªè¿›ç¨‹å¯¹åº”äº†ä¸€ä¸ª rank çš„è¿›ç¨‹ï¼Œæ•´ä¸ªåˆ†å¸ƒå¼ç”±è®¸å¤š rank å®Œæˆã€‚
- nodeï¼šç‰©ç†èŠ‚ç‚¹ï¼Œå¯ä»¥æ˜¯ä¸€å°æœºå™¨ä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªå®¹å™¨ï¼ŒèŠ‚ç‚¹å†…éƒ¨å¯ä»¥æœ‰å¤šä¸ª GPUã€‚
- rank ä¸ local_rankï¼š rank æ˜¯æŒ‡åœ¨æ•´ä¸ªåˆ†å¸ƒå¼ä»»åŠ¡ä¸­è¿›ç¨‹çš„åºå·ï¼›local_rank æ˜¯æŒ‡åœ¨ä¸€ä¸ª node ä¸Šè¿›ç¨‹çš„ç›¸å¯¹åºå·ï¼Œlocal_rank åœ¨ node ä¹‹é—´ç›¸äº’ç‹¬ç«‹ã€‚ï¼ˆæ³¨æ„ï¼šåœ¨ä»£ç ä¸­ï¼Œä¼šä½¿ç”¨ local_rank æ¥æŒ‡å®š GPUï¼Œå¹¶ä¸” local_rank å’Œå®é™…çš„ gpu ç¼–å·å­˜åœ¨æ˜ å°„å…³ç³»ï¼Œæ¯”å¦‚ï¼ŒæŒ‡å®š gpu 4,5 è¿›è¡Œè®­ç»ƒï¼Œlocal_rank ä»ç„¶æ˜¯ 0,1ï¼Œä½†å‰ææ˜¯è¦å…ˆè®¾ç½® os.environ['CUDA_VISIBLE_DEVICES'] = "4,5"ï¼‰ã€‚
- nnodesã€node_rank ä¸ nproc_per_nodeï¼š nnodes æ˜¯æŒ‡ç‰©ç†èŠ‚ç‚¹æ•°é‡ï¼Œnode_rank æ˜¯ç‰©ç†èŠ‚ç‚¹çš„åºå·ï¼›nproc_per_node æ˜¯æŒ‡æ¯ä¸ªç‰©ç†èŠ‚ç‚¹ä¸Šé¢è¿›ç¨‹çš„æ•°é‡ã€‚
- word size ï¼š å…¨å±€ï¼ˆä¸€ä¸ªåˆ†å¸ƒå¼ä»»åŠ¡ï¼‰ä¸­ï¼Œrank çš„æ•°é‡ã€‚
> ğŸ’¡ RANK æ˜¯å…¨å±€è¿›ç¨‹çš„åºå·ï¼Œè€Œ LOCAL_RANK å¯ä»¥ç†è§£ä¸ºæ¯ä¸ªè¿›ç¨‹ä¸­çº¿ç¨‹çš„åºå·ã€‚

# Examples
æˆ‘ä»¬ä»¥ PyTorch ä¸¾ä¾‹ï¼ŒDDP å…·ä½“å®ç°æ–¹å¼å¦‚ä¸‹:

1. è·å–å…¨å±€å˜é‡

    ```python
    import os
    
    LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))
    RANK = int(os.getenv('RANK', -1))
    WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))
    ```

2. æ ¹æ® LOCAL_RANK ç»™æ¯ä¸€ä¸ªè®¡ç®—èŠ‚ç‚¹åˆ†é… GPU

    ```python
	if LOCAL_RANK != -1:
		assert torch.cuda.device_count() > LOCAL_RANK, 'insufficient CUDA devices for DDP command'
		print("torch.cuda.device_count():", torch.cuda.device_count())
		torch.cuda.set_device(LOCAL_RANK)
		device = torch.device("cuda", LOCAL_RANK)
		dist.init_process_group(backend="nccl" if dist.is_nccl_available() else "gloo")
    ```

3. ä»…åœ¨ä¸»è¿›ç¨‹ä¸­ä¿å­˜æ—¥å¿—ä¿¡æ¯ï¼Œé¿å…æ‰“å°æ··ä¹±

    ```python
    # logger
    if RANK in {-1, 0}:
    	logger.info("Message...")
    
    # pbar
    pbar = enumerate(train_loader)
	if RANK in {-1, 0}:
		pbar = tqdm(pbar, total=steps_per_epoch, desc='Epoch {}/{}'.format(epoch, args.max_epochs))
    ```

4. åœ¨å•æœºå•å¡ä»¥å¤–çš„æ¨¡å¼ï¼Œéœ€è¦è®¾ç½®åˆ†å¸ƒå¼é‡‡æ ·å™¨

    ```python
    from torch.utils.data import distributed
    
    dataset = Dataset()
    sampler = None if LOCAL_RANK == -1 else distributed.DistributedSampler(dataset, shuffle=True)
    ```

5. åœ¨ä¸»è¿›ç¨‹ä»¥å¤–çš„è¿›ç¨‹ä¸­å°è£… DDP

    ```python
    from torch.nn.parallel import DistributedDataParallel as DDP
    
    if RANK != -1:
    	# Sync batch norm
    	model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)
    	# DDP
    	model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)
    ```

# Shell Commonds
åœ¨å‘½ä»¤è¡Œè¿è¡Œè®­ç»ƒè„šæœ¬æ—¶æˆ‘ä»¬å¯ä»¥é€šè¿‡æŒ‡å®šèŠ‚ç‚¹æˆ– GPU è®¾å¤‡æ¥æ§åˆ¶ DDP è¿›ç¨‹ï¼Œä»¥ä¸‹ä¸ºå¸¸è§çš„å½¢å¼ï¼š

1. å•æœºå•å¡
	```bash
	python main.py --device 0
	```

2. å•æœºå¤šå¡
	```bash
	python -m torch.distributed.launch --nproc_per_node 2 main.py
	# æŒ‡å®šæŸå‡ å¼ GPU
	python -m torch.distributed.launch --nproc_per_node 2 main.py --device 0,3
	```

3. å¤šæœºå¤šå¡
	```bash
	# - master_address: masterè¿›ç¨‹çš„ç½‘ç»œåœ°å€
	# - master_port: masterè¿›ç¨‹çš„ä¸€ä¸ªç«¯å£ï¼Œé»˜è®¤29500ï¼Œä½¿ç”¨å‰éœ€è¦ç¡®è®¤ç«¯å£æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨
	# èŠ‚ç‚¹0
	python -m torch.distributed.launch --nproc_node=8 
	        --nnodes=2 --node_rank=0 --master_address="192.168.0.1"
	        --master_port=12345 train.py
	# èŠ‚ç‚¹1
	python -m torch.distributed.launch --nproc_node=8 
	        --nnodes=2 --node_rank=1 --master_address="192.168.0.1"
	        --master_port=12345 train.py
	```