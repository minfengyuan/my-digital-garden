---
{"dg-publish":true,"title":"炼丹技法","created":"2024-01-16 15:11","updated":"2024-01-29 15:00","tags":["pytorch","deep-learning"],"dg-path":"Wiki/炼丹技法.md","permalink":"/Wiki/炼丹技法/","dgPassFrontmatter":true,"noteIcon":"1"}
---


本文主要用来记录笔者在日常开发过程中常用的方法。

# Python 训练时指定 GPU

> 参考自 [文章](https://blog.csdn.net/qq_36663518/article/details/107815195)

## 在 Py 文件里指定

```python
import os

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" #可不写
os.environ["CUDA_VISIBLE_DEVICES"] = "0" #0就是指定GPU 0 跑实验，可按需修改成其他GPU

# 设置定量的GPU使用量(如果是TensorFlow框架）

import tensorflow as tf
config = tf.ConfigProto() 
config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 占用GPU90%的显存 
session = tf.Session(config=config)

# 设置最小的GPU使用量

config = tf.ConfigProto() 
config.gpu_options.allow_growth = True
```

## (or) 在终端指定

```bash
CUDA_VISIBLE_DEVICES=0 python your_code.py #0表示GPU0，按需修改
```

# 动态查看 GPU 占用率

```bash
watch -n1 nvidia-smi 
数字`1` 表示每1秒刷新界面
```

# 使用 Screen 解决 Ssh 连接中断导致的训练中断问题

1. 安装 screen

    ```bash
    sudo apt-get install screen
    ```

2. 创建一个会话窗口 (Session)

    ```bash
    $ screen -S SessionName
    screen -S train
    ```

3. 列出所有的会话窗口

    ```bash
    $ screen -ls
    There is a screen on:
            1622.train      (01/31/21 19:32:12)     (Attached)
    1 Socket in /run/screen/S-root.
    ```

4. 进入指定窗口

    ```bash
    screen -r 1622 # 1622为session的连接id
    # 或者也可以
    screen -r SessionName # 对应1622的话此处应为train
    ```

5. 与窗口分离

    ```bash
    screen -d 1622
    ```

6. 重新连接窗口

    ```bash
    screen -x 1622
    # 如有需要可以先分离再重新连接
    screen -d -r 1622
    ```
 
7. 删除窗口

    ```bash
    screen -X -S 1622 quit
    ``` 

# 远程查看部署在服务器上的 Tensorboard

## Windows 系统

1. 在 Windows 系统装一个 Xshell 或 FinalShell，编辑 SSH 连接→隧道→添加，类型为 `local`（本地），源主机（绑定 ip）填 `127.0.0.1`，端口随意设置一个未使用的端口如 `12345`，目标主机为服务器 ip，目标端口一般是 `6006`，也可改成其他端口。
2. 在服务器上运行 `tensorboard --logdir='logs' --port 6006`。
3. 在本机打开网页 `127.0.0.1:12345`

## Mac 或 Linux 系统

1. 在登录远程服务器的时候使用命令：

    ```bash
    ssh -L 16006:127.0.0.1:6006 account@server.address
    ```

2. 训练完模型之后使用如下命令：

    ```bash
    tensorboard --logdir="/path/to/log-directory"
    ```

3. 最后，在本地访问地址：http://127.0.0.1:16006/

# 估算一个深度模型的计算量和参数

	借助THOP: PyTorch-OpCounter

*Official URL*: https://github.com/Lyken17/pytorch-OpCounter

1. 安装

    ```bash
    pip install thop
    # or
    pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git
    ```

2. 使用

	- 基础用法

    ```python
    from torchvision.models import resnet50
    from thop import profile
    model = resnet50()
    input = torch.randn(1, 3, 224, 224)
    macs, params = profile(model, inputs=(input,))
    ```

   - 对第三方模块定义规则
   
    ```python
    class YourModule(nn.Module)
    	# your definition

    def count_your_model(model, x, y):
    	# your rule here

    input = torch.randn(1, 3, 224, 224)
    macs, params = profile(model, inputs=(input,),
    						custom_ops={YourModule: count_your_model})
    ```

   - 改善 profile 输出可读性

    调用 `thop.clever_format` 对 profile 结果格式化

    ```python
    from thop import clever_format
    macs, params = clever_format([macs, params], "%.3f")
    ```

# Automatic Mixed Precision (AMP)

举例:

```python
import torch

scaler = torch.cuda.amp.GradScaler(enabled=True)

optimizer.zero_grad()

# Casts operations to mixed precision
with torch.cuda.amp.autocast(enabled=True):
	loss = model(data)

# Scales the loss, and call backward() to create scaled gradients
scaler.scale(loss).backward()
# Unscales gradients and calls or skips optimizer.step()
scaler.step(optimizer)
# Updates the scale for next iteration
scaler.update()
```