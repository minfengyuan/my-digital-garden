---
{"dg-publish":true,"title":"ç‚¼ä¸¹æŠ€æ³•","created":"2024/01/16, 15:11","updated":"2024/01/17, 08:41","tags":["pytorch","deep-learning"],"dg-path":"ç®—æ³•å¼€å‘/ç‚¼ä¸¹æŠ€æ³•.md","permalink":"/ç®—æ³•å¼€å‘/ç‚¼ä¸¹æŠ€æ³•/","dgPassFrontmatter":true,"noteIcon":""}
---


æœ¬æ–‡ä¸»è¦ç”¨æ¥è®°å½•ç¬”è€…åœ¨æ—¥å¸¸å¼€å‘è¿‡ç¨‹ä¸­å¸¸ç”¨çš„æ–¹æ³•ã€‚

# Python è®­ç»ƒæ—¶æŒ‡å®š GPU

> å‚è€ƒè‡ª [æ–‡ç« ](https://blog.csdn.net/qq_36663518/article/details/107815195)

## åœ¨ Py æ–‡ä»¶é‡ŒæŒ‡å®š

```python
import os

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" #å¯ä¸å†™
os.environ["CUDA_VISIBLE_DEVICES"] = "0" #0å°±æ˜¯æŒ‡å®šGPU 0 è·‘å®éªŒï¼Œå¯æŒ‰éœ€ä¿®æ”¹æˆå…¶ä»–GPU

# è®¾ç½®å®šé‡çš„GPUä½¿ç”¨é‡(å¦‚æœæ˜¯TensorFlowæ¡†æ¶ï¼‰

import tensorflow as tf
config = tf.ConfigProto() 
config.gpu_options.per_process_gpu_memory_fraction = 0.9 # å ç”¨GPU90%çš„æ˜¾å­˜ 
session = tf.Session(config=config)

# è®¾ç½®æœ€å°çš„GPUä½¿ç”¨é‡

config = tf.ConfigProto() 
config.gpu_options.allow_growth = True
```

## (or) åœ¨ç»ˆç«¯æŒ‡å®š

```bash
CUDA_VISIBLE_DEVICES=0 python your_code.py #0è¡¨ç¤ºGPU0ï¼ŒæŒ‰éœ€ä¿®æ”¹
```

# åŠ¨æ€æŸ¥çœ‹ GPU å ç”¨ç‡

```bash
watch -n1 nvidia-smi 
æ•°å­—`1` è¡¨ç¤ºæ¯1ç§’åˆ·æ–°ç•Œé¢
```

# ä½¿ç”¨ Screen è§£å†³ Ssh è¿æ¥ä¸­æ–­å¯¼è‡´çš„è®­ç»ƒä¸­æ–­é—®é¢˜

1. å®‰è£… screen

    ```bash
    sudo apt-get install screen
    ```

2. åˆ›å»ºä¸€ä¸ªä¼šè¯çª—å£ (Session)

    ```bash
    $ screen -S SessionName
    screen -S train
    ```

3. åˆ—å‡ºæ‰€æœ‰çš„ä¼šè¯çª—å£

    ```bash
    $ screen -ls
    There is a screen on:
            1622.train      (01/31/21 19:32:12)     (Attached)
    1 Socket in /run/screen/S-root.
    ```

4. è¿›å…¥æŒ‡å®šçª—å£

    ```bash
    screen -r 1622 # 1622ä¸ºsessionçš„è¿æ¥id
    # æˆ–è€…ä¹Ÿå¯ä»¥
    screen -r SessionName # å¯¹åº”1622çš„è¯æ­¤å¤„åº”ä¸ºtrain
    ```

5. ä¸çª—å£åˆ†ç¦»

    ```bash
    screen -d 1622
    ```

6. é‡æ–°è¿æ¥çª—å£

    ```bash
    screen -x 1622
    # å¦‚æœ‰éœ€è¦å¯ä»¥å…ˆåˆ†ç¦»å†é‡æ–°è¿æ¥
    screen -d -r 1622
    ```
 
7. åˆ é™¤çª—å£

    ```bash
    screen -X -S 1622 quit
    ``` 

# è¿œç¨‹æŸ¥çœ‹éƒ¨ç½²åœ¨æœåŠ¡å™¨ä¸Šçš„ Tensorboard

## Windows ç³»ç»Ÿ

1. åœ¨ Windows ç³»ç»Ÿè£…ä¸€ä¸ª Xshell æˆ– FinalShellï¼Œç¼–è¾‘ SSH è¿æ¥â†’éš§é“â†’æ·»åŠ ï¼Œç±»å‹ä¸º `local`ï¼ˆæœ¬åœ°ï¼‰ï¼Œæºä¸»æœºï¼ˆç»‘å®š ipï¼‰å¡« `127.0.0.1`ï¼Œç«¯å£éšæ„è®¾ç½®ä¸€ä¸ªæœªä½¿ç”¨çš„ç«¯å£å¦‚ `12345`ï¼Œç›®æ ‡ä¸»æœºä¸ºæœåŠ¡å™¨ ipï¼Œç›®æ ‡ç«¯å£ä¸€èˆ¬æ˜¯ `6006`ï¼Œä¹Ÿå¯æ”¹æˆå…¶ä»–ç«¯å£ã€‚
2. åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ `tensorboard --logdir='logs' --port 6006`ã€‚
3. åœ¨æœ¬æœºæ‰“å¼€ç½‘é¡µ `127.0.0.1:12345`

## Mac æˆ– Linux ç³»ç»Ÿ

1. åœ¨ç™»å½•è¿œç¨‹æœåŠ¡å™¨çš„æ—¶å€™ä½¿ç”¨å‘½ä»¤ï¼š

    ```bash
    ssh -L 16006:127.0.0.1:6006 account@server.address
    ```

2. è®­ç»ƒå®Œæ¨¡å‹ä¹‹åä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼š

    ```bash
    tensorboard --logdir="/path/to/log-directory"
    ```

3. æœ€åï¼Œåœ¨æœ¬åœ°è®¿é—®åœ°å€ï¼šhttp://127.0.0.1:16006/

# ä¼°ç®—ä¸€ä¸ªæ·±åº¦æ¨¡å‹çš„è®¡ç®—é‡å’Œå‚æ•°

	å€ŸåŠ©THOP: PyTorch-OpCounter

*Official URL*: https://github.com/Lyken17/pytorch-OpCounter

1. å®‰è£…

    ```bash
    pip install thop
    # or
    pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git
    ```

2. ä½¿ç”¨

	- åŸºç¡€ç”¨æ³•

    ```python
    from torchvision.models import resnet50
    from thop import profile
    model = resnet50()
    input = torch.randn(1, 3, 224, 224)
    macs, params = profile(model, inputs=(input,))
    ```

   - å¯¹ç¬¬ä¸‰æ–¹æ¨¡å—å®šä¹‰è§„åˆ™
   
    ```python
    class YourModule(nn.Module)
    	# your definition

    def count_your_model(model, x, y):
    	# your rule here

    input = torch.randn(1, 3, 224, 224)
    macs, params = profile(model, inputs=(input,),
    						custom_ops={YourModule: count_your_model})
    ```

   - æ”¹å–„ profile è¾“å‡ºå¯è¯»æ€§

    è°ƒç”¨ `thop.clever_format` å¯¹ profile ç»“æœæ ¼å¼åŒ–

    ```python
    from thop import clever_format
    macs, params = clever_format([macs, params], "%.3f")
    ```

# DistributedDataParallel (DDP)

## Concepts

- rankï¼šç”¨äºè¡¨ç¤ºè¿›ç¨‹çš„ç¼–å·/åºå·ï¼ˆåœ¨ä¸€äº›ç»“æ„å›¾ä¸­ rank æŒ‡çš„æ˜¯è½¯èŠ‚ç‚¹ï¼Œrank å¯ä»¥çœ‹æˆä¸€ä¸ªè®¡ç®—å•ä½ï¼‰ï¼Œæ¯ä¸€ä¸ªè¿›ç¨‹å¯¹åº”äº†ä¸€ä¸ª rank çš„è¿›ç¨‹ï¼Œæ•´ä¸ªåˆ†å¸ƒå¼ç”±è®¸å¤š rank å®Œæˆã€‚
- nodeï¼šç‰©ç†èŠ‚ç‚¹ï¼Œå¯ä»¥æ˜¯ä¸€å°æœºå™¨ä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªå®¹å™¨ï¼ŒèŠ‚ç‚¹å†…éƒ¨å¯ä»¥æœ‰å¤šä¸ª GPUã€‚
- rank ä¸ local_rankï¼š rank æ˜¯æŒ‡åœ¨æ•´ä¸ªåˆ†å¸ƒå¼ä»»åŠ¡ä¸­è¿›ç¨‹çš„åºå·ï¼›local_rank æ˜¯æŒ‡åœ¨ä¸€ä¸ª node ä¸Šè¿›ç¨‹çš„ç›¸å¯¹åºå·ï¼Œlocal_rank åœ¨ node ä¹‹é—´ç›¸äº’ç‹¬ç«‹ã€‚ï¼ˆæ³¨æ„ï¼šåœ¨ä»£ç ä¸­ï¼Œä¼šä½¿ç”¨ local_rank æ¥æŒ‡å®š GPUï¼Œå¹¶ä¸” local_rank å’Œå®é™…çš„ gpu ç¼–å·å­˜åœ¨æ˜ å°„å…³ç³»ï¼Œæ¯”å¦‚ï¼ŒæŒ‡å®š gpu 4,5 è¿›è¡Œè®­ç»ƒï¼Œlocal_rank ä»ç„¶æ˜¯ 0,1ï¼Œä½†å‰ææ˜¯è¦å…ˆè®¾ç½® os.environ['CUDA_VISIBLE_DEVICES'] = "4,5"ï¼‰ã€‚
- nnodesã€node_rank ä¸ nproc_per_nodeï¼š nnodes æ˜¯æŒ‡ç‰©ç†èŠ‚ç‚¹æ•°é‡ï¼Œnode_rank æ˜¯ç‰©ç†èŠ‚ç‚¹çš„åºå·ï¼›nproc_per_node æ˜¯æŒ‡æ¯ä¸ªç‰©ç†èŠ‚ç‚¹ä¸Šé¢è¿›ç¨‹çš„æ•°é‡ã€‚
- word size ï¼š å…¨å±€ï¼ˆä¸€ä¸ªåˆ†å¸ƒå¼ä»»åŠ¡ï¼‰ä¸­ï¼Œrank çš„æ•°é‡ã€‚

	> ğŸ’¡ RANK æ˜¯å…¨å±€è¿›ç¨‹çš„åºå·ï¼Œè€Œ LOCAL_RANK å¯ä»¥ç†è§£ä¸ºæ¯ä¸ªè¿›ç¨‹ä¸­çº¿ç¨‹çš„åºå·ã€‚

## Examples

1. è·å–å…¨å±€å˜é‡

    ```python
    import os
    
    LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))
    RANK = int(os.getenv('RANK', -1))
    WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))
    ```

2. æ ¹æ® LOCAL_RANK ç»™æ¯ä¸€ä¸ªè®¡ç®—èŠ‚ç‚¹åˆ†é… GPU

    ```python
    if LOCAL_RANK != -1:
            assert torch.cuda.device_count() > LOCAL_RANK, 'insufficient CUDA devices for DDP command'
            print("torch.cuda.device_count():", torch.cuda.device_count())
            torch.cuda.set_device(LOCAL_RANK)
            device = torch.device("cuda", LOCAL_RANK)
            dist.init_process_group(backend="nccl" if dist.is_nccl_available() else "gloo")
    ```

3. ä»…åœ¨ä¸»è¿›ç¨‹ä¸­ä¿å­˜æ—¥å¿—ä¿¡æ¯ï¼Œé¿å…æ‰“å°æ··ä¹±

    ```python
    # logger
    if RANK in {-1, 0}:
    	logger.info("Message...")
    
    # pbar
    pbar = enumerate(train_loader)
            if RANK in {-1, 0}:
                pbar = tqdm(pbar, total=steps_per_epoch, desc='Epoch {}/{}'.format(epoch, args.max_epochs))
    ```

4. åœ¨å•æœºå•å¡ä»¥å¤–çš„æ¨¡å¼ï¼Œéœ€è¦è®¾ç½®åˆ†å¸ƒå¼é‡‡æ ·å™¨

    ```python
    from torch.utils.data import distributed
    
    dataset = Dataset()
    sampler = None if LOCAL_RANK == -1 else distributed.DistributedSampler(dataset, shuffle=True)
    ```

5. åœ¨ä¸»è¿›ç¨‹ä»¥å¤–çš„è¿›ç¨‹ä¸­å°è£… DDP
    
    ```python
    from torch.nn.parallel import DistributedDataParallel as DDP
    
    if RANK != -1:
    	# Sync batch norm
    	model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)
    	# DDP
    	model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)
    ```

## Shell Commonds

```bash
# å‘½ä»¤è¡ŒæŒ‡å®šGPUè®¾å¤‡

# å•æœºå•å¡
python main.py --device 0

# å•æœºå¤šå¡
python -m torch.distributed.launch --nproc_per_node 2 main.py
# æŒ‡å®šæŸå‡ å¼ GPU
python -m torch.distributed.launch --nproc_per_node 2 main.py --device 0,3

# å¤šæœºå¤šå¡
# - master_address: masterè¿›ç¨‹çš„ç½‘ç»œåœ°å€
# - master_port: masterè¿›ç¨‹çš„ä¸€ä¸ªç«¯å£ï¼Œé»˜è®¤29500ï¼Œä½¿ç”¨å‰éœ€è¦ç¡®è®¤ç«¯å£æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨
# èŠ‚ç‚¹0
python -m torch.distributed.launch --nproc_node=8 
        --nnodes=2 --node_rank=0 --master_address="192.168.0.1"
        --master_port=12345 train.py
# èŠ‚ç‚¹1
python -m torch.distributed.launch --nproc_node=8 
        --nnodes=2 --node_rank=1 --master_address="192.168.0.1"
        --master_port=12345 train.py
```

# Automatic Mixed Precision (AMP)

ä¸¾ä¾‹:

```python
import torch

scaler = torch.cuda.amp.GradScaler(enabled=True)

optimizer.zero_grad()

# Casts operations to mixed precision
with torch.cuda.amp.autocast(enabled=True):
	loss = model(data)

# Scales the loss, and call backward() to create scaled gradients
scaler.scale(loss).backward()
# Unscales gradients and calls or skips optimizer.step()
scaler.step(optimizer)
# Updates the scale for next iteration
scaler.update()
```