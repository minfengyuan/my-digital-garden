---
{"dg-publish":true,"title":"炼丹技法","created":"2024/01/16, 15:11","updated":"2024/01/17, 08:41","tags":["pytorch","deep-learning"],"dg-path":"算法开发/炼丹技法.md","permalink":"/算法开发/炼丹技法/","dgPassFrontmatter":true,"noteIcon":""}
---


本文主要用来记录笔者在日常开发过程中常用的方法。

# Python 训练时指定 GPU

> 参考自 [文章](https://blog.csdn.net/qq_36663518/article/details/107815195)

## 在 Py 文件里指定

```python
import os

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" #可不写
os.environ["CUDA_VISIBLE_DEVICES"] = "0" #0就是指定GPU 0 跑实验，可按需修改成其他GPU

# 设置定量的GPU使用量(如果是TensorFlow框架）

import tensorflow as tf
config = tf.ConfigProto() 
config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 占用GPU90%的显存 
session = tf.Session(config=config)

# 设置最小的GPU使用量

config = tf.ConfigProto() 
config.gpu_options.allow_growth = True
```

## (or) 在终端指定

```bash
CUDA_VISIBLE_DEVICES=0 python your_code.py #0表示GPU0，按需修改
```

# 动态查看 GPU 占用率

```bash
watch -n1 nvidia-smi 
数字`1` 表示每1秒刷新界面
```

# 使用 Screen 解决 Ssh 连接中断导致的训练中断问题

1. 安装 screen

    ```bash
    sudo apt-get install screen
    ```

2. 创建一个会话窗口 (Session)

    ```bash
    $ screen -S SessionName
    screen -S train
    ```

3. 列出所有的会话窗口

    ```bash
    $ screen -ls
    There is a screen on:
            1622.train      (01/31/21 19:32:12)     (Attached)
    1 Socket in /run/screen/S-root.
    ```

4. 进入指定窗口

    ```bash
    screen -r 1622 # 1622为session的连接id
    # 或者也可以
    screen -r SessionName # 对应1622的话此处应为train
    ```

5. 与窗口分离

    ```bash
    screen -d 1622
    ```

6. 重新连接窗口

    ```bash
    screen -x 1622
    # 如有需要可以先分离再重新连接
    screen -d -r 1622
    ```
 
7. 删除窗口

    ```bash
    screen -X -S 1622 quit
    ``` 

# 远程查看部署在服务器上的 Tensorboard

## Windows 系统

1. 在 Windows 系统装一个 Xshell 或 FinalShell，编辑 SSH 连接→隧道→添加，类型为 `local`（本地），源主机（绑定 ip）填 `127.0.0.1`，端口随意设置一个未使用的端口如 `12345`，目标主机为服务器 ip，目标端口一般是 `6006`，也可改成其他端口。
2. 在服务器上运行 `tensorboard --logdir='logs' --port 6006`。
3. 在本机打开网页 `127.0.0.1:12345`

## Mac 或 Linux 系统

1. 在登录远程服务器的时候使用命令：

    ```bash
    ssh -L 16006:127.0.0.1:6006 account@server.address
    ```

2. 训练完模型之后使用如下命令：

    ```bash
    tensorboard --logdir="/path/to/log-directory"
    ```

3. 最后，在本地访问地址：http://127.0.0.1:16006/

# 估算一个深度模型的计算量和参数

	借助THOP: PyTorch-OpCounter

*Official URL*: https://github.com/Lyken17/pytorch-OpCounter

1. 安装

    ```bash
    pip install thop
    # or
    pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git
    ```

2. 使用

	- 基础用法

    ```python
    from torchvision.models import resnet50
    from thop import profile
    model = resnet50()
    input = torch.randn(1, 3, 224, 224)
    macs, params = profile(model, inputs=(input,))
    ```

   - 对第三方模块定义规则
   
    ```python
    class YourModule(nn.Module)
    	# your definition

    def count_your_model(model, x, y):
    	# your rule here

    input = torch.randn(1, 3, 224, 224)
    macs, params = profile(model, inputs=(input,),
    						custom_ops={YourModule: count_your_model})
    ```

   - 改善 profile 输出可读性

    调用 `thop.clever_format` 对 profile 结果格式化

    ```python
    from thop import clever_format
    macs, params = clever_format([macs, params], "%.3f")
    ```

# DistributedDataParallel (DDP)

## Concepts

- rank：用于表示进程的编号/序号（在一些结构图中 rank 指的是软节点，rank 可以看成一个计算单位），每一个进程对应了一个 rank 的进程，整个分布式由许多 rank 完成。
- node：物理节点，可以是一台机器也可以是一个容器，节点内部可以有多个 GPU。
- rank 与 local_rank： rank 是指在整个分布式任务中进程的序号；local_rank 是指在一个 node 上进程的相对序号，local_rank 在 node 之间相互独立。（注意：在代码中，会使用 local_rank 来指定 GPU，并且 local_rank 和实际的 gpu 编号存在映射关系，比如，指定 gpu 4,5 进行训练，local_rank 仍然是 0,1，但前提是要先设置 os.environ['CUDA_VISIBLE_DEVICES'] = "4,5"）。
- nnodes、node_rank 与 nproc_per_node： nnodes 是指物理节点数量，node_rank 是物理节点的序号；nproc_per_node 是指每个物理节点上面进程的数量。
- word size ： 全局（一个分布式任务）中，rank 的数量。

	> 💡 RANK 是全局进程的序号，而 LOCAL_RANK 可以理解为每个进程中线程的序号。

## Examples

1. 获取全局变量

    ```python
    import os
    
    LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))
    RANK = int(os.getenv('RANK', -1))
    WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))
    ```

2. 根据 LOCAL_RANK 给每一个计算节点分配 GPU

    ```python
    if LOCAL_RANK != -1:
            assert torch.cuda.device_count() > LOCAL_RANK, 'insufficient CUDA devices for DDP command'
            print("torch.cuda.device_count():", torch.cuda.device_count())
            torch.cuda.set_device(LOCAL_RANK)
            device = torch.device("cuda", LOCAL_RANK)
            dist.init_process_group(backend="nccl" if dist.is_nccl_available() else "gloo")
    ```

3. 仅在主进程中保存日志信息，避免打印混乱

    ```python
    # logger
    if RANK in {-1, 0}:
    	logger.info("Message...")
    
    # pbar
    pbar = enumerate(train_loader)
            if RANK in {-1, 0}:
                pbar = tqdm(pbar, total=steps_per_epoch, desc='Epoch {}/{}'.format(epoch, args.max_epochs))
    ```

4. 在单机单卡以外的模式，需要设置分布式采样器

    ```python
    from torch.utils.data import distributed
    
    dataset = Dataset()
    sampler = None if LOCAL_RANK == -1 else distributed.DistributedSampler(dataset, shuffle=True)
    ```

5. 在主进程以外的进程中封装 DDP
    
    ```python
    from torch.nn.parallel import DistributedDataParallel as DDP
    
    if RANK != -1:
    	# Sync batch norm
    	model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)
    	# DDP
    	model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)
    ```

## Shell Commonds

```bash
# 命令行指定GPU设备

# 单机单卡
python main.py --device 0

# 单机多卡
python -m torch.distributed.launch --nproc_per_node 2 main.py
# 指定某几张GPU
python -m torch.distributed.launch --nproc_per_node 2 main.py --device 0,3

# 多机多卡
# - master_address: master进程的网络地址
# - master_port: master进程的一个端口，默认29500，使用前需要确认端口是否被其他程序占用
# 节点0
python -m torch.distributed.launch --nproc_node=8 
        --nnodes=2 --node_rank=0 --master_address="192.168.0.1"
        --master_port=12345 train.py
# 节点1
python -m torch.distributed.launch --nproc_node=8 
        --nnodes=2 --node_rank=1 --master_address="192.168.0.1"
        --master_port=12345 train.py
```

# Automatic Mixed Precision (AMP)

举例:

```python
import torch

scaler = torch.cuda.amp.GradScaler(enabled=True)

optimizer.zero_grad()

# Casts operations to mixed precision
with torch.cuda.amp.autocast(enabled=True):
	loss = model(data)

# Scales the loss, and call backward() to create scaled gradients
scaler.scale(loss).backward()
# Unscales gradients and calls or skips optimizer.step()
scaler.step(optimizer)
# Updates the scale for next iteration
scaler.update()
```